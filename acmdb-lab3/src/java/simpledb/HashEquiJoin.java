package simpledb;

import java.util.*;

/**
 * The Join operator implements the relational join operation.
 */
public class HashEquiJoin extends Operator {

    private static final long serialVersionUID = 1L;

    private final JoinPredicate p;
    private DbIterator child1, child2;
    private HashMap<Field, List<Tuple>> hashMap;
    private Tuple tuple1;
    transient Iterator<Tuple> listIt = null;

    /**
     * Constructor. Accepts to children to join and the predicate to join them
     * on
     * 
     * @param p
     *            The predicate to use to join the children
     * @param child1
     *            Iterator for the left(outer) relation to join
     * @param child2
     *            Iterator for the right(inner) relation to join
     */
    public HashEquiJoin(JoinPredicate p, DbIterator child1, DbIterator child2) {
        // some code goes here
        this.p = p;
        this.child1 = child1;
        this.child2 = child2;
        hashMap = new HashMap<>();
    }

    public JoinPredicate getJoinPredicate() {
        // some code goes here
        return p;
    }

    public TupleDesc getTupleDesc() {
        // some code goes here
        return TupleDesc.merge(child1.getTupleDesc(), child2.getTupleDesc());
    }
    
    public String getJoinField1Name()
    {
        // some code goes here
        return child1.getTupleDesc().getFieldName(p.getField1());
    }

    public String getJoinField2Name()
    {
        // some code goes here
        return child1.getTupleDesc().getFieldName(p.getField2());
    }
    
    public void open() throws DbException, NoSuchElementException,
            TransactionAbortedException {
        // some code goes here
        super.open();
        child1.open();
        child2.open();
    }

    public void close() {
        // some code goes here
        super.close();
        child1.close();
        child2.close();
    }

    public void rewind() throws DbException, TransactionAbortedException {
        // some code goes here
        child1.rewind();
        child2.rewind();
        hashMap.clear();
        tuple1 = null;
    }

    /**
     * Returns the next tuple generated by the join, or null if there are no
     * more tuples. Logically, this is the next tuple in r1 cross r2 that
     * satisfies the join predicate. There are many possible implementations;
     * the simplest is a nested loops join.
     * <p>
     * Note that the tuples returned from this particular implementation of Join
     * are simply the concatenation of joining tuples from the left and right
     * relation. Therefore, there will be two copies of the join attribute in
     * the results. (Removing such duplicate columns can be done with an
     * additional projection operator if needed.)
     * <p>
     * For example, if one tuple is {1,2,3} and the other tuple is {1,5,6},
     * joined on equality of the first column, then this returns {1,2,3,1,5,6}.
     * 
     * @return The next matching tuple.
     * @see JoinPredicate#filter
     */
    protected Tuple fetchNext() throws TransactionAbortedException, DbException {
        // some code goes here
        int tuple1NumFields = child1.getTupleDesc().numFields();
        int tuple2NumFields = child2.getTupleDesc().numFields();

        // If this is the first call to fetchNext(), build the hashMap, get the first tuple1 and listIt
        if (tuple1 == null) {
            // Build the hashMap
            while (child2.hasNext()) {
                Tuple tuple2 = child2.next();
                Field tuple2Key = tuple2.getField(p.getField2());
                if (hashMap.containsKey(tuple2Key)) {
                    List<Tuple> tupleList = hashMap.get(tuple2Key);
                    tupleList.add(tuple2);
                }
                else {
                    List<Tuple> tupleList = new ArrayList<>();
                    tupleList.add(tuple2);
                    hashMap.put(tuple2Key, tupleList);
                }

            }

            // Get the first tuple1 and listIt
            while (child1.hasNext()) {
                tuple1 = child1.next();
                Field tuple1Key = tuple1.getField(p.getField1());
                if (hashMap.containsKey(tuple1Key)) {
                    listIt = hashMap.get(tuple1Key).listIterator();
                    break;
                }
            }
            if (listIt == null) {
                return null;
            }
        }

        while (true) {
            if (listIt.hasNext()) { // Get the next tuple2
                Tuple tuple2 = listIt.next();
                Tuple joinedTuple = new Tuple(getTupleDesc());
                int i = 0;
                while (i < tuple1NumFields) {
                    joinedTuple.setField(i, tuple1.getField(i));
                    ++i;
                }
                while (i < tuple1NumFields + tuple2NumFields) {
                    joinedTuple.setField(i, tuple2.getField(i - tuple1NumFields));
                    ++i;
                }
                return joinedTuple;
            }
            listIt = null;  // When listIt reaches the end, get the next tuple1 and listIt
            while (child1.hasNext()) {
                tuple1 = child1.next();
                Field tuple1Key = tuple1.getField(p.getField1());
                if (hashMap.containsKey(tuple1Key)) {
                    listIt = hashMap.get(tuple1Key).listIterator();
                    break;
                }
            }
            if (listIt == null) {
                return null;
            }
        }
    }

    @Override
    public DbIterator[] getChildren() {
        // some code goes here
        DbIterator[] children = {child1, child2};
        return children;
    }

    @Override
    public void setChildren(DbIterator[] children) {
        // some code goes here
        child1 = children[0];
        child2 = children[1];
    }
    
}
